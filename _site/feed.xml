<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-06-09T05:45:58+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Soyoung’s blog</title><subtitle>Soyoung's blog that records about what I learned</subtitle><author><name>Soyoung Yoon</name></author><entry><title type="html">Notes On Naacl 2021 Oral Presentation On Semantic Parsing</title><link href="http://localhost:4000/notes-on-NAACL-2021-oral-presentation-on-semantic-parsing/" rel="alternate" type="text/html" title="Notes On Naacl 2021 Oral Presentation On Semantic Parsing" /><published>2021-06-09T00:00:00+09:00</published><updated>2021-06-09T00:00:00+09:00</updated><id>http://localhost:4000/notes-on-NAACL-2021-oral-presentation-on-semantic-parsing</id><content type="html" xml:base="http://localhost:4000/notes-on-NAACL-2021-oral-presentation-on-semantic-parsing/">&lt;p&gt;Here are the brief notes that I took from listening to the oral presentations of great authors (mainly focused on text-to-SQL)&lt;/p&gt;

&lt;h3 id=&quot;latent-compositional-representations-improve-systematic-generalization-in-grounded-answering&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/2007.00266.pdf&quot;&gt;Latent Compositional Representations improve systematic generalization in grounded answering&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;They make trees on all latent&lt;/p&gt;

&lt;p&gt;Tree helps whether the model is really correct or not.&lt;/p&gt;

&lt;p&gt;Beam search can help&lt;/p&gt;

&lt;h3 id=&quot;learning-from-executions-for-semantic-parsing&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.219.pdf&quot;&gt;Learning from executions for semantic parsing&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Executable program &amp;lt;- model that only uses labeled data&lt;/p&gt;

&lt;p&gt;Lower bound that uses the labeled examples&lt;/p&gt;

&lt;p&gt;Grammar-based &amp;lt;- forcing at training time, more correct that you do that in test time.&lt;/p&gt;

&lt;p&gt;Assume that topk is not always executable&lt;/p&gt;

&lt;p&gt;Pretrained parser already has some knowledge about what is right and what is wrong -&amp;gt; have to somehow renormalize the topk items&lt;/p&gt;

&lt;p&gt;Trying to utilize the unlabeled data. How are we going to do learning from that?&lt;/p&gt;

&lt;p&gt;not all the programs are not executable. Assign non-executable programs have very small loss.&lt;/p&gt;

&lt;p&gt;Executability is a free signal. It is weak because we don’t know the answer.&lt;/p&gt;

&lt;p&gt;We maximize marginal likelihood for all possible executable programs -&amp;gt; but all is infeasible. We utilize the beam searched query.  But it seems kind of unfair. Encourage model to explore more executable models during program(motivation)&lt;/p&gt;

&lt;p&gt;provide sparsity on the executable programs &amp;lt;- They can be executable but not correct(second motiviation)&lt;/p&gt;

&lt;p&gt;y is our program, 0 otherwise. We want p (distribution of our parser) to be as similar as Q. Executable programs are always in this family. There is only 6 executable programs. It is discrete but the domain for executable program is continuous(?)&lt;/p&gt;

&lt;p&gt;Distance metric is KL divergence. As long as p is close to Qx, we are happy. It could be anywhere to q. x&lt;/p&gt;

&lt;p&gt;Grammar-based decoding &amp;lt;- Limit search space to executable programs.&lt;/p&gt;

&lt;p&gt;We already do that. Grammatical != Executable difference? &amp;lt;- column type constraints?&lt;/p&gt;

&lt;h3 id=&quot;compositional-generalization-for-neural-semantic-parsing-via-span-level-supervised-attention&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.225.pdf&quot;&gt;Compositional generalization for neural semantic parsing via span-level supervised attention&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/illustrations/compgen.png&quot; alt=&quot;image-20210609023241594&quot; /&gt;&lt;/p&gt;

&lt;p&gt;-&amp;gt; span-level supervised attention&lt;/p&gt;

&lt;p&gt;encourage models with span-level alignments? Semantic parser is seq-to-seq example.&lt;/p&gt;

&lt;p&gt;contains syntac-level MT limitations&lt;/p&gt;

&lt;p&gt;uses the outputs from this syntactic level alignments -&amp;gt; find bounding box&lt;/p&gt;

&lt;h3 id=&quot;incorporating-external-knowledge-to-enhance-tabular-reasoning&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.224.pdf&quot;&gt;Incorporating external knowledge to enhance tabular reasoning&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;how do you represent tabular data to text? Can we incoporate external knowledge to model?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;poor representation of tabular information&lt;/li&gt;
  &lt;li&gt;Implicit lexical knowledge&lt;/li&gt;
  &lt;li&gt;presensce of distracting&lt;/li&gt;
  &lt;li&gt;missing domain knowledge about keys&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We use entity types for better table representation. Prune table according to it.&lt;/p&gt;

&lt;p&gt;Preprocessing helps on alpha1 and alpha3.&lt;/p&gt;

&lt;h3 id=&quot;learning-to-synthesize-data-for-semantic-parsing&quot;&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.220.pdf&quot;&gt;Learning to synthesize data for semantic parsing&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;similar to back translation&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/illustrations/synsemparse.png&quot; alt=&quot;image-3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hand-crafting rules are not very good objective -&amp;gt; you don’t know what the dataset will look like.&lt;/p&gt;

&lt;p&gt;Utterance doesn’t make sense, but maybe the model can learn from the correspondance.&lt;/p&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">Here are the brief notes that I took from listening to the oral presentations of great authors (mainly focused on text-to-SQL)</summary></entry><entry><title type="html">Notes On Getting Into Grad School Naacl 2021</title><link href="http://localhost:4000/Notes-on-getting-into-grad-school-NAACL-2021/" rel="alternate" type="text/html" title="Notes On Getting Into Grad School Naacl 2021" /><published>2021-06-09T00:00:00+09:00</published><updated>2021-06-09T00:00:00+09:00</updated><id>http://localhost:4000/Notes-on-getting-into-grad-school-NAACL-2021</id><content type="html" xml:base="http://localhost:4000/Notes-on-getting-into-grad-school-NAACL-2021/">&lt;h2 id=&quot;notes-on-webminar-getting-into-grad-school-naacl-2021&quot;&gt;Notes on Webminar: Getting into grad school (NAACL 2021)&lt;/h2&gt;

&lt;h3 id=&quot;what-do-you-think-sets-apart-a-strong-application-for-graduate-study&quot;&gt;What do you think sets apart a strong application for graduate study?&lt;/h3&gt;

&lt;p&gt;Vlad Nicule) Differs so much&lt;/p&gt;

&lt;p&gt;Motivation / Recommendation letters matter so much&lt;/p&gt;

&lt;p&gt;Good Letter? Relevant papers that shows your field of NLP&lt;/p&gt;

&lt;h3 id=&quot;what-are-the-criteria-to-keep-in-mind-while-choosing-a-grad-school-a-research-group-and-a-phd-advisor&quot;&gt;What are the criteria to keep in mind while choosing a grad school, a research group and a PhD advisor?&lt;/h3&gt;

&lt;p&gt;Elizabeth Nielsen) 2 things to look for:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;How they are to work with? -&amp;gt; more important, hard to figure out&lt;/li&gt;
  &lt;li&gt;How well do they do research?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Is your supervisor overfed with work? what kind of dynamics are they included? competitive? Find single-author papers / How well do they explain? It’s a good indicator of great advisor(?)&lt;/p&gt;

&lt;h3 id=&quot;how-do-you-structure-statement-of-purpose--research-proposal&quot;&gt;How do you structure statement of purpose / research proposal?&lt;/h3&gt;

&lt;p&gt;Nick McKenna) Statement of purpose is very important. To convince reader that you have an idea of project that is useful / can do that. Motivation of problem - State of field - How you would approach your problem. Not have to be exact, but more thoughtthrough it is, more convincing it would be. It’s just like who you are, because each of us have a different story. And definately tell your story!&lt;/p&gt;

&lt;h3 id=&quot;what-were-the-most-useful-resources-in-getting-into-grad-school&quot;&gt;What were the most useful resources in getting into grad school?&lt;/h3&gt;

&lt;p&gt;Salomon Kabongo Kabenamualu) Twitter is valuable! (GOOD~~)&lt;/p&gt;

&lt;h3 id=&quot;how-did-you-face-imposter-syndrome-during-grad-school-and-your-application-process&quot;&gt;How did you face imposter syndrome, during grad school and your application process?&lt;/h3&gt;

&lt;p&gt;Sian Gooding)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;External ) You compell yourself to people around you&lt;/li&gt;
  &lt;li&gt;Internal ) You doubt your skills  &amp;lt;- Effected more highly&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For 1 - Anti-savi &amp;lt;- Do it reversely - If they didn’t get this intern, didn’t get this paper accepted…&lt;/p&gt;

&lt;p&gt;You’re seeing the best path of the people you look on twitter. You keep that on mind (being inspired v.s. being intimidated) &amp;lt;- Parallelized on how am I going to get to this&lt;/p&gt;

&lt;p&gt;For 2 -Try not to be a perfectionist &amp;lt;- become one of it because you’re so self-critical. Be kind to yourself.&lt;/p&gt;

&lt;p&gt;Nick) I face that myself a lot. Other than papers &amp;amp; application process. There are other things you can do that you can show that you are good at research. (e.g. participating at a reading group. Able to show up every week, do discussion, talk about papers - good way to get a feel for the field. And got good recommendation letters by that.)&lt;/p&gt;

&lt;p&gt;Even if it doesn’t make it to paper, it is still a good progress.&lt;/p&gt;

&lt;h3 id=&quot;what-aspects-of-the-labor-environment-should-i-keep-an-eye-out-for&quot;&gt;What aspects of the labor environment should I keep an eye out for?&lt;/h3&gt;

&lt;p&gt;Vlad Niculae) Group dynamics, healthy environment with collegues…&lt;/p&gt;

&lt;p&gt;Also, environment is important (very different from country to country and school to school)&lt;/p&gt;

&lt;p&gt;Having a contract &amp;lt;- expectations are clear. Cannot do what is not asked&lt;/p&gt;

&lt;p&gt;Are you going to be an employee in the University? or not? This is very important.&lt;/p&gt;

&lt;p&gt;Pension? Visa aspects? Technical error in a corner? Immigrant? Salary’s differnt. Is there a grad student union? If you face injustice, where can you go to? &amp;lt;- So different. &amp;amp; Important&lt;/p&gt;

&lt;p&gt;Can you change advisors? Is there a history of this?&lt;/p&gt;

&lt;p&gt;Mental health resources at university?&lt;/p&gt;

&lt;h3 id=&quot;how-do-you-conduct-or-manage-online-research-collaborations-especially-under-current-circumstances&quot;&gt;How do you conduct or manage online research collaborations, especially under current circumstances?&lt;/h3&gt;

&lt;p&gt;Sebastian Ruder ) Just be kind to your collaborators.&lt;/p&gt;

&lt;p&gt;Regarding broad research collaboration - most collabo was remotely done. I think communications is more important. Writing one more email / one more chat is important (to sync with each other)&lt;/p&gt;

&lt;h3 id=&quot;how-does-one-keep-up-with-the-latest-research-and-papers&quot;&gt;How does one keep up with the latest research and papers?&lt;/h3&gt;

&lt;p&gt;Nick McKenna) 3 things you can do&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Going out and find research papers yourself&lt;/li&gt;
  &lt;li&gt;Mining by google scholar - targeted searches. Getting researches sent to you (news feed by arxiv, semantic scholar on keywords)&lt;/li&gt;
  &lt;li&gt;Form a peer group, share some interests. Meet together and discuss a paper.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;when-and-how-did-you-get-into-nlp-research&quot;&gt;When and how did you get into NLP research?&lt;/h3&gt;

&lt;p&gt;Salomon Kabongo Kabenamualu) Opportunity - wasn’t able to search for a mathmatician job - got ML job - … Why didn’t I see this option before?!?!&lt;/p&gt;

&lt;h3 id=&quot;how-to-approach-potential-research-mentors&quot;&gt;How to approach potential research mentors?&lt;/h3&gt;

&lt;p&gt;Elizabeth Nielsen) Read their website first and read the instructions.&lt;/p&gt;

&lt;p&gt;Reach them first (e.g. conference and so on) and then email.&lt;/p&gt;

&lt;p&gt;Make your email easier to read. Good sharp students that can help students they can enjoy advising. Don’t ask super open-ended questions….&lt;/p&gt;

&lt;p&gt;Stay away from open-ended questions / vague questions / long emails…. &amp;lt;- This doesn’t make people think that you can make their life easier..&lt;/p&gt;

&lt;h3 id=&quot;how-was-your-first-publication-process-looked--experience-like&quot;&gt;How was your first publication process looked / experience like?&lt;/h3&gt;

&lt;p&gt;Sian Gooding) Had no idea what I was doing. Once done once, it becomes so much easier next time. Checking it hundred times because I was so nervous. It is very normal to get papers rejected. That is NOT the end of life. Peer review is amazing and you can learn a lot from it. It’s okay for it to be rejected. It can make the paper a lot better.&lt;/p&gt;

&lt;h3 id=&quot;what-pre-doctoral-research-experiences-you-think-could-better-prepare-a-student-for-graduate-study&quot;&gt;What pre-doctoral research experiences you think could better prepare a student for graduate study?&lt;/h3&gt;

&lt;p&gt;Reading a bunch of research. Learn to judge papers. Learn to look at paper and see what you can do after this research. How can I actually come up with research questions that I can &lt;strong&gt;test&lt;/strong&gt;? (It’s not like I want to study NLG.)&lt;/p&gt;

&lt;p&gt;….. My hand hurts…&lt;/p&gt;

&lt;h3 id=&quot;what-career-experiences-do-you-think-are-most-fruitful-for-building-a-professional-identity-in-nlp&quot;&gt;What career experiences do you think are most fruitful for building a professional identity in NLP?&lt;/h3&gt;

&lt;p&gt;internal identity / research taste / What are your personal preferences? (beautiful theory / Useful practice / … / writing beautiful papers?) &amp;lt;- how you work yourself. Useful in finding your collaborators - who can do complementary things&lt;/p&gt;

&lt;p&gt;Figure out what your overall research area is. Communicate more on surveys/blog posts.&lt;/p&gt;

&lt;h3 id=&quot;how-do-you-grapple-with-the-ethical-implications-of-developing-nlp-including-biases-in-algorithms-and-data&quot;&gt;How do you grapple with the ethical implications of developing NLP, including biases in algorithms and data?&lt;/h3&gt;

&lt;p&gt;Careful not just on relying on GLEU score.&lt;/p&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">Notes on Webminar: Getting into grad school (NAACL 2021)</summary></entry><entry><title type="html">Naacl 2021 Paper Review About Semantic Parsing</title><link href="http://localhost:4000/NAACL-2021-paper-review-about-semantic-parsing/" rel="alternate" type="text/html" title="Naacl 2021 Paper Review About Semantic Parsing" /><published>2021-05-31T00:00:00+09:00</published><updated>2021-05-31T00:00:00+09:00</updated><id>http://localhost:4000/NAACL-2021-paper-review-about-semantic-parsing</id><content type="html" xml:base="http://localhost:4000/NAACL-2021-paper-review-about-semantic-parsing/">&lt;p&gt;This page is a draft page, to take notes on recent text-to-SQL methods that is accepted in NAACL 2021.&lt;/p&gt;

&lt;p&gt;The related papers are listed in random order.&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.103.pdf&quot;&gt;DuoRAT: Towards Simpler Text-to-SQL Models&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.105.pdf&quot;&gt;Structure-Grounded Pretraining for Text-to-SQL&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.441.pdf&quot;&gt;ShadowGNN: Graph Projection Neural Network for Text-to-SQL Parser&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&quot;https://www.aclweb.org/anthology/2021.naacl-main.33.pdf&quot;&gt;Meta-Learning for Domain Generalization in Semantic Parsing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&quot;https://arxiv.org/pdf/2104.05819.pdf&quot;&gt;Learning from Executions for Semantic Parsing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6] &lt;a href=&quot;https://arxiv.org/pdf/2104.05827.pdf&quot;&gt;Learning to Synthesize Data for Semantic Parsing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It seems like most of the SOTA semantic parsing papers are from one person: &lt;a href=&quot;https://berlino.github.io/&quot;&gt;Bailin Wang&lt;/a&gt;. He is the author of RAT-SQL and [4], [5], and [6].&lt;/p&gt;

&lt;h3 id=&quot;4&quot;&gt;[4]&lt;/h3&gt;

&lt;p&gt;Intuition: &lt;em&gt;Gradient Steps&lt;/em&gt; that improve source-domain performance should also improve target-domain performance&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DG-MAML (Domain Generalization with Model-Agnostic Meta-Learning)
    &lt;ul&gt;
      &lt;li&gt;a training algorithm that helps a parser acheive better domain generalization&lt;/li&gt;
      &lt;li&gt;training domain and test(eval) domain are different.&lt;/li&gt;
      &lt;li&gt;Meta-Train
        &lt;ul&gt;
          &lt;li&gt;SGD of loss from virtual source domain&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Meta-Test
        &lt;ul&gt;
          &lt;li&gt;compute loss from virtual target domain&lt;/li&gt;
          &lt;li&gt;minimize the &lt;strong&gt;joint&lt;/strong&gt; loss on both source and target domain -&amp;gt; require the gradient step beneficial to target domain&lt;/li&gt;
          &lt;li&gt;Can be viewed as regularization of gradient updates in additional to objective of conventional supervised learning&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Applying DG-MAML on RAT-SQL
    &lt;ul&gt;
      &lt;li&gt;evaluate on two zero-shot text-to-SQL - English/Chinese spider&lt;/li&gt;
      &lt;li&gt;achieves near SOTA on Spider, and SOTA on Chinese spider&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Questions to ask TBU
More notes TBU&lt;/p&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">This page is a draft page, to take notes on recent text-to-SQL methods that is accepted in NAACL 2021.</summary></entry><entry><title type="html">Linux Tips And Notes</title><link href="http://localhost:4000/Linux-tips-and-notes/" rel="alternate" type="text/html" title="Linux Tips And Notes" /><published>2021-04-05T00:00:00+09:00</published><updated>2021-04-05T00:00:00+09:00</updated><id>http://localhost:4000/Linux-tips-and-notes</id><content type="html" xml:base="http://localhost:4000/Linux-tips-and-notes/">&lt;p&gt;ㅎ.. 언젠가부터 내 블로그가 잊어먹지 않도록 글을 끄적하는 장소로 바뀌어버린 것
같다. 논문만 된다면… 그 때 정말 제대로 된 informative한 글을 남기겠다…ㅠㅠ&lt;/p&gt;

&lt;p&gt;nvidia-smi를 실시간으로 볼 수 있는 command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;watch -n0.1 nvidia-smi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Recursively list all subdirectories inside list&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ls -LR
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;check disk size and path&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lsblk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Github crediential 저장&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git config credential.helper store --global
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Colorscheme and color problem solved by terminfo&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install ncurses-term
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remove __pycache__files into git&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git rm -r --cached . &amp;amp;&amp;amp; git add . &amp;amp;&amp;amp; git commit -m &quot;fixing .gitignore&quot;
&lt;/code&gt;&lt;/pre&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">ㅎ.. 언젠가부터 내 블로그가 잊어먹지 않도록 글을 끄적하는 장소로 바뀌어버린 것 같다. 논문만 된다면… 그 때 정말 제대로 된 informative한 글을 남기겠다…ㅠㅠ</summary></entry><entry><title type="html">Semantic Parsing References</title><link href="http://localhost:4000/Semantic-Parsing-references/" rel="alternate" type="text/html" title="Semantic Parsing References" /><published>2021-03-12T00:00:00+09:00</published><updated>2021-03-12T00:00:00+09:00</updated><id>http://localhost:4000/Semantic-Parsing-references</id><content type="html" xml:base="http://localhost:4000/Semantic-Parsing-references/">&lt;p&gt;Semantic Parsing References:
Spider explanation: https://medium.com/@tao.yu/spider-one-more-step-towards-natural-language-interfaces-to-databases-62298dc6df3c, https://arxiv.org/pdf/1809.08887.pdf
Spider recent/official: https://arxiv.org/pdf/2012.12627.pdf https://arxiv.org/pdf/2012.10309v1.pdf
WikiTableQuestions 1st: https://arxiv.org/pdf/2005.08314v1.pdf
WikiSQL: https://arxiv.org/pdf/1910.07179v5.pdf
SQLova: https://arxiv.org/pdf/1902.01069.pdf
evaluation: https://arxiv.org/pdf/2010.02840.pdf&lt;/p&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">Semantic Parsing References: Spider explanation: https://medium.com/@tao.yu/spider-one-more-step-towards-natural-language-interfaces-to-databases-62298dc6df3c, https://arxiv.org/pdf/1809.08887.pdf Spider recent/official: https://arxiv.org/pdf/2012.12627.pdf https://arxiv.org/pdf/2012.10309v1.pdf WikiTableQuestions 1st: https://arxiv.org/pdf/2005.08314v1.pdf WikiSQL: https://arxiv.org/pdf/1910.07179v5.pdf SQLova: https://arxiv.org/pdf/1902.01069.pdf evaluation: https://arxiv.org/pdf/2010.02840.pdf</summary></entry><entry><title type="html">Nlp References</title><link href="http://localhost:4000/NLP-references/" rel="alternate" type="text/html" title="Nlp References" /><published>2020-12-14T00:00:00+09:00</published><updated>2020-12-14T00:00:00+09:00</updated><id>http://localhost:4000/NLP-references</id><content type="html" xml:base="http://localhost:4000/NLP-references/">&lt;p&gt;시간이 난다면 들어볼만한, 혹은 읽어볼만한 유익한 NLP reference들 정리.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://soundcloud.com/nlp-highlights&quot;&gt;Soundcloud NLP highlights&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nlpwithfriends.com/&quot;&gt;NLP seminar&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=EbpU4p_0hes&quot;&gt;NIPS workshop on interpreting predictions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=gprIzglUW1s&amp;amp;t=6921s&quot;&gt;EMNLP workshop on interpreting predictions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">시간이 난다면 들어볼만한, 혹은 읽어볼만한 유익한 NLP reference들 정리.</summary></entry><entry><title type="html">Model의 State_dict 일부분만 Load하기</title><link href="http://localhost:4000/Model%EC%9D%98-state_dict-%EC%9D%BC%EB%B6%80%EB%B6%84%EB%A7%8C-load%ED%95%98%EA%B8%B0/" rel="alternate" type="text/html" title="Model의 State_dict 일부분만 Load하기" /><published>2020-12-02T00:00:00+09:00</published><updated>2020-12-02T00:00:00+09:00</updated><id>http://localhost:4000/Model%EC%9D%98-state_dict-%EC%9D%BC%EB%B6%80%EB%B6%84%EB%A7%8C-load%ED%95%98%EA%B8%B0</id><content type="html" xml:base="http://localhost:4000/Model%EC%9D%98-state_dict-%EC%9D%BC%EB%B6%80%EB%B6%84%EB%A7%8C-load%ED%95%98%EA%B8%B0/">&lt;p&gt;정말 오랜만에 글을 쓰는것같다.
8월부터 11월까지 너무 바빴어서, github blog posting이 소홀해졌던 것 같다.&lt;/p&gt;

&lt;p&gt;오늘은 pretrained pytorch model을 loading해오려고 했는데, pytorch version과 여러 환경세팅이 맞지 않아서 모델의 state_dict에 있는 key가 matching이 되지 않아 모델의 pretrained weight가 불려오지 않는 문제가 있었다.
아래는 모델을 로딩해오는 예시이다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import torch.nn as nn
import torch
from transformers impoort *
...
model = BertForSequenceClassification.from_pretrained('bert-base-uncased')
model = nn.DataParallel(model)
saved_checkpoint = torch.load(CHECKPOINT_PATH, map_location=torch.device('cpu'))
model.load_state_dict(checkpoint)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이 코드를 실행하면 model을 train했던 환경과 local에서 돌리는 환경이 달라서 아래와 같은 에러가 나타난다…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Traceback (most recent call last):
  File &quot;train.py&quot;, line 182, in &amp;lt;module&amp;gt;
    aa = Trainer(USE_NSML)
  File &quot;train.py&quot;, line 68, in __init__
    self.load_and_eval(path)
  File &quot;train.py&quot;, line 178, in load_and_eval
    model.load_state_dict(checkpoint)
  File &quot;/Users/user/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py&quot;, line 1051, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for DataParallel:
        Missing key(s) in state_dict: &quot;module.bert.embeddings.position_ids&quot;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;찾아보니, &lt;code&gt;model.load_state_dict&lt;/code&gt;를 할 때 strict하게 로딩해오지 않고 가능한것만 로딩해올수있는 좀더 flexible한 option이 있었다!
바로 첫 코드 마지막줄을&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# model.load_state_dict(checkpoint)
model.load_state_dict(checkpoint, strict=False)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;로 바꿔주면 되는것!
물론 이렇게 하면 &lt;code&gt;_IncompatibleKeys(missing_keys=['module.bert.embeddings.position_ids'], unexpected_keys=[])&lt;/code&gt; 이런 info가 print되긴 하지만…
어쨌든 embeddings.position_ids 를 제외한 모든 key에 대한 weight를 로딩시켜올 수 있다.
이 option이 아니면 일일이 key를 순회하면서 weight를 로딩해올뻔했다…ㅠㅠ&lt;/p&gt;

&lt;p&gt;이렇게 로딩해온 모델이 정말 제대로 weight이 들어갔는지를 보기위해 pdb를 이용하여 직접 찍어 보았다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(Pdb) model.state_dict()['module.classifier.weight']
tensor([[-0.0090, -0.0031,  0.0340,  ...,  0.0068, -0.0230, -0.0238],
        [-0.0099,  0.0067, -0.0177,  ...,  0.0013,  0.0326, -0.0063],
        [ 0.0313, -0.0120, -0.0136,  ...,  0.0040,  0.0181,  0.0040]])
(Pdb) model.load_state_dict(checkpoint, strict=False)
_IncompatibleKeys(missing_keys=['module.bert.embeddings.position_ids'], unexpected_keys=[])
(Pdb) model.state_dict()['module.classifier.weight']
tensor([[ 0.0015,  0.0072, -0.0019,  ..., -0.0207, -0.0180,  0.0103],
        [ 0.1731,  0.0091,  0.0032,  ...,  0.0844,  0.0104,  0.0086],
        [-0.0104,  0.0330,  0.0011,  ..., -0.0107,  0.0184,  0.0088]])
(Pdb)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;제대로 바뀐걸 볼 수 있다!&lt;/p&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">정말 오랜만에 글을 쓰는것같다. 8월부터 11월까지 너무 바빴어서, github blog posting이 소홀해졌던 것 같다.</summary></entry><entry><title type="html">Pytorch Model 일부 Layer만 Freeze 하기</title><link href="http://localhost:4000/pytorch-model-%EC%9D%BC%EB%B6%80-layer%EB%A7%8C-freeze-%ED%95%98%EA%B8%B0/" rel="alternate" type="text/html" title="Pytorch Model 일부 Layer만 Freeze 하기" /><published>2020-08-24T00:00:00+09:00</published><updated>2020-08-24T00:00:00+09:00</updated><id>http://localhost:4000/pytorch-model-%EC%9D%BC%EB%B6%80-layer%EB%A7%8C-freeze-%ED%95%98%EA%B8%B0</id><content type="html" xml:base="http://localhost:4000/pytorch-model-%EC%9D%BC%EB%B6%80-layer%EB%A7%8C-freeze-%ED%95%98%EA%B8%B0/">&lt;p&gt;task-specific한 Model training을 할 때, 기존의 pretrained model weight를
가져와서 하는 경우가 많이 있다.
여러 논문들에서도 BERT와 같이 pretrained된 대형 모델에서, layer 몇 개만
추가해주면 어떤 NLP task던 from scratch에서부터 training하는 것보다
좋은 성능을 낸다는 것을 입증하고 있다.&lt;/p&gt;

&lt;p&gt;지금 나는 classification model을 만들고 있는데, 역시 마찬가지로
huggingface에서 공개한 pretrained model을 사용 중이다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from transformers import *
bert = BertModel.from_pretrained('bert-base-uncased')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;이 모델 뒤에, 간단한 linear - tanh - linear layer만 추가해서
model ouptut로 classification에 쓰는 label을 내도록 하기 위해선&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import torch
import torch.nn as nn
from transformers import *

class ClassificationModel(nn.Module):
    def __init__(self, pretrained_model='bert-base-uncased', num_labels=2):
        super(ClassificationModel, self).__init__()
        self.bert = BertModel.from_pretrained(pretrained_model)
        self.linear = nn.Sequential(nn.Linear(768, 128),
                                    nn.Tanh(),
                                    nn.Linear(128, num_labels))

    def forward(self, x):
        all_hidden, pooler = self.bert(**x)
        pooled_output = torch.mean(all_hidden, 1)
        predict = self.linear(pooled_output)
        return predict
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;요런 식으로 구현하면 된다.&lt;/p&gt;

&lt;p&gt;그런데!!! 문제가 생겼다.&lt;/p&gt;

&lt;p&gt;model training을 진행해 보니, 첫 번째 epoch를 돈 이후가 가장 성능이 좋았고,
그 뒤로부턴 성능이 계속계속 떨어졌다.&lt;/p&gt;

&lt;p&gt;문제가 뭐일까? 생각하는 와중에,
기존 pretrained model의 weight를 과도하게 bias시켜서(forgetting) 그런게 아닐까? 라는 생각이 들었다.&lt;/p&gt;

&lt;p&gt;그래서, 기존 pretrained model의 weight는 freeze시키고, 추가한 &lt;code&gt;nn.Sequential&lt;/code&gt; layer의
weight만 training해보면 어떨까 라는생각이 들었다.&lt;/p&gt;

&lt;p&gt;방법은 의외로 간단했다.
일단 위의 코드를 선언한 다음&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; model = ClassificationModel()
&amp;gt;&amp;gt;&amp;gt; model.state_dict().keys()
odict_keys(['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight',
......'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'linear.0.weight', 'linear.0.bias', 'linear.2.weight', 'linear.2.bias'])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;를 해주면, 모델 안에 선언되어있는 다양한 weight들의 key값을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 우리가 바꿔주고 싶은 것은 오직 &lt;code&gt;'linear.0.weight', 'linear.0.bias', 'linear.2.weight', 'linear.2.bias'&lt;/code&gt;이것들!&lt;/p&gt;

&lt;p&gt;일단 모든 weight를 다 freeze시켜준다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;for para in model.parameters():
...     para.requires_grad = False
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그리고 해당 layer만 &lt;code&gt;requires_grad&lt;/code&gt;를 켜주면 끝!
…..이라고 생각했지만 큰 오산이었다….왜냐..? 
&lt;code&gt;model.linear.0.weight&lt;/code&gt;에서 0이 .. .숫자가 있어서, 저런 방식으로 접근이 불가능했기 때문ㅠㅠㅠㅠㅠ&lt;/p&gt;

&lt;p&gt;만약에 이름이 &lt;code&gt;fc1&lt;/code&gt; 뭐 이런거였으면&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;model.fc1.weight.requires_grad = True
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;요렇게 해결해주면 되는 간단한 문제였지만,.. 불가능했기 때문에 다른 방법을 쓰기로 했다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;for name, param in model.named_parameters():
&amp;gt;&amp;gt;&amp;gt;    if name in ['linear.0.weight', 'linear.2.weight']:
&amp;gt;&amp;gt;&amp;gt;        param.requires_grad = True
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;요렇게 해서 해결하게 되었다…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;추가: 원래 Model training할때 (꼭) 이렇게(만은) 하지는 않는다고 한다. 그리고, 내 모델은 forgetting이 되어서 성능이 내려갔다기 보다는 training data자체가 워낙 작아서,
이미 한epoch만에 수렴을 했고, 계속 overfitting되었던게 문제였던것같다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">task-specific한 Model training을 할 때, 기존의 pretrained model weight를 가져와서 하는 경우가 많이 있다. 여러 논문들에서도 BERT와 같이 pretrained된 대형 모델에서, layer 몇 개만 추가해주면 어떤 NLP task던 from scratch에서부터 training하는 것보다 좋은 성능을 낸다는 것을 입증하고 있다.</summary></entry><entry><title type="html">Methods Related To Mixup</title><link href="http://localhost:4000/methods-related-to-mixup/" rel="alternate" type="text/html" title="Methods Related To Mixup" /><published>2020-08-11T00:00:00+09:00</published><updated>2020-08-11T00:00:00+09:00</updated><id>http://localhost:4000/methods-related-to-mixup</id><content type="html" xml:base="http://localhost:4000/methods-related-to-mixup/">&lt;p&gt;이번에 연구 주제와 관련되어서 &lt;a href=&quot;https://arxiv.org/pdf/1710.09412.pdf&quot;&gt;mixup&lt;/a&gt; 기반의 논문들을 읽어보고 공부하게 되었다.
여기서 중요하다고 느꼈던 점과 읽었던 부분들을 정리해보려고 한다.
시간이 지나면 다시 까먹을 것 같아서, 미리미리 정리해두는게 좋을것 같다.
(정리한 부분은 순전히 내가 읽고 받아들인 대로 적은 것이기 떄문에, 틀린 부분이 있을 수 있고,
잘못된 부분이 있다면 댓글로 알려주시면 정말 감사하겠습니다..ㅎㅎ)&lt;/p&gt;

&lt;p&gt;먼저 &lt;a href=&quot;https://arxiv.org/pdf/1710.09412.pdf&quot;&gt;mixup&lt;/a&gt;이라는 논문에서 말하고자 하는 요지는 간단하다.&lt;/p&gt;

&lt;p&gt;이 논문의 저자는 &lt;strong&gt;mixup&lt;/strong&gt;이라는 term을 사용하는데, 결국&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://latex.codecogs.com/gif.latex?\tilde{x}%20=%20\lambda{x}_i%20+%20(1-\lambda){x}_j&quot; alt=&quot;equation&quot; /&gt;, where x_i, x_j are raw input vectors,
&lt;img src=&quot;https://latex.codecogs.com/gif.latex?\tilde{y}%20=%20\lambda{y}_i%20+%20(1-\lambda){y}_j&quot; alt=&quot;equation&quot; /&gt;, where y_i, y_j are one-hot label encodings&lt;/p&gt;

&lt;p&gt;이 수식이 논문의 모든 것을 설명해준다고 해도 과언이 아니다..(Markdown 으로 수식 표현하느라 힘들었다..)
즉, virtual example을 만드는데 있어서, x_i와 x_j를 일정한 비율(lambda)로 잘 섞어서, output label도 역시 섞어서 만들어준다는 것이다.&lt;/p&gt;

&lt;p&gt;이렇게 하면 뭐가 좋은가?&lt;/p&gt;

&lt;p&gt;이전의 training 기법들은 &lt;code&gt;ERM&lt;/code&gt;(Empirical Risk Minimization)을 중심으로 learning을 시켰다. ERM이란, 경험적으로 주어진 set X와 Y에 대해서만 risk를 최소화한다는 것으로, 이렇게 하게 된다면 Adversraial attack에 취약하게 되고, generalizaiton하는 대신
empirical data에 대한 memorize를 하게 되는 방향으로 training된다고 볼 수 있다.
따라서 이렇게 되는 것을 막기 위해 training data augmentation을 하게 되는데, 
이것을 &lt;code&gt;VRM&lt;/code&gt;(Vicinal Risk Minimization)이라고 한다.&lt;/p&gt;

&lt;p&gt;VRM이란, empirical data의 주변부(vicinity) 분포를 적절하게 모델링하고
이 data distribution에 대한 Risk를 minimization하는 것을 objective로 삼는 것이다. Semi-supervised learning의 한 종류로 봐도 좋을 것 같다.&lt;/p&gt;

&lt;p&gt;또 여기서는 &lt;code&gt;manifold mixup&lt;/code&gt;라는 표현도 사용했는데, 처음에는 manifold가 무슨 뜻인지 몰라서 찾아보았다.
manifold를 간단히 설명하자면, 두 개의 data가 eucledian distance상으로는 가까이 있지만, 사실상 비유클리디안 형태의 분포로 있기 때문에 가까운게 멀수도있고, 먼게 가까울수도 있다는 말이다.
즉, manifold mixup이란 두 Input x1과 x2의 함수를 취한 결과값 f(x1) 과 f(x2) 두개를 위의 식과 같이 섞어준다는 간단한 말로 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;여기까지가 ERM, VRM, 그리고 manifold mixup term에 대해 내가 이해한 바를 정리한 글이다.&lt;/p&gt;

&lt;p&gt;그럼 이게 [PuzzleMix]랑 어떻게 관련이 되는지를 소개하도록 하겠다.
Puzzlemix는 기존에 있었던 mixup을 기반으로 한 data augmentation을 수행하는데, 크게 두 가지의 contribution을 주장한다.
첫 번째는, 기존에는 무작위로 섞었다면, 여기서는 sailency를 각 이미지에서 뽑아서 그 sailency를 보존하는 이미지를 만든다.
두 번째로는, 각 이미지에 존재하는 local statistics를 보존한다.&lt;/p&gt;

&lt;p&gt;여기서 sailency란, “중요한 부분”을 나타내는 의미로서, 본문상에서는 vision분야에서는 foreground object, speech에서는 
prominant syallable, language에서는 informative textual unit등이 있다고 소개하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/equations/puzzlemix.png&quot; alt=&quot;equation1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PuzzleMix에서 formulate하는 수식은 위와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/illustrations/puzzlemix1.png&quot; alt=&quot;equation1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위에 있는 절댓값에 씌여져 있는 두 term이 input data x0 와 x1에 해당하는 masking 및 optimal transport를 적용한 결과값이고,
나머지 beta, gamma, eta, alpha가 noise data에 대한 smoothness를 결정한다.
아래 그림의 첫 줄은 각 두 이미지를 얼마나 섞을 것인가(lambda)가 달라짐에 따라 달라지는 결과 output이고,&lt;/p&gt;

&lt;p&gt;두 번째 줄은 smoothness beta 와 mask r 를 얼마나 줄것인가 에 따라 달라지는 결과이다.&lt;/p&gt;

&lt;p&gt;즉, 만들어진 virtual image상에서 각 픽셀에 기존의 이미지를 얼마 비율로 섞을 것인가를 의미한다. 이것이 r의 값이다.
해당 픽셀에 r이 1/2이라면 output image는 두 Input image의 픽셀값이 골고루 둘다 들어가는 것이고, r이 0이거나 1이면
두 이미지 중 하나의 값만 들어가게 되는 것이다. 이렇게 골고루 적절히 잘 섞이게 하여 hyperparameter를 조정하여 이미지를
만들어낼 수 있다. 수식에서 pi에 해당하는 것은 각 이미지를 어떻게 optimal 하게 transport시킬 수 있는가에 대한 것이다.
(&lt;a href=&quot;https://mathematical-coffees.github.io/slides/mc01-courty.pdf&quot;&gt;optimal transport 관련 참고한 설명글&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;그 뒤에서 논문이 설명하는 것은 어떻게 하면 optimal transport를 빠르게 할 수 있는지(mini batch단위로 computation을 돌리는데 o(n^3)의
time complexity를 갖고 있기 때문에 그대로 적용하기 보다는 여러 가지 증명과정을 거쳐서 approximation이 가능하다는 것을 보이고
빠르게 계산하게 된다)를 증명하고 방법을 알려주고 있다.&lt;/p&gt;

&lt;p&gt;그 뒤는 이렇게 하는 것이 adversarial example을 만드는 것과 비슷한 효과를 낸다, 또는 adversarial example을 어떠한
추가적인 computational cost 없이 만드는 것이 가능하다는 이야기를 한다. (이 부분은 정확히 이해하지 못했다. 추후 더 읽고 이해한 후
수정할 예정이다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/illustrations/puzzlemix2.png&quot; alt=&quot;image1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;논문의 마지막은 Vanilla, Input, Manifold, CutMix, AugMix 등 다양한 mixup 기반의 메소드들 보다 PuzzleMix이 월등히 높은 성능 낸다는 것을 보여주고 있다.
puzzleMix(half)란, 기존의 training방법보다 총 iteration하는 epoch수를 반으로 줄이고 initial learning rate를 2배 해서 training을 돌린 것을 이야기한다.
computational cost 대비 fair comparison을 위해 추가하였다고 말하고 있다.
또, top-1 외에 top-2 dataset에 대해 다른 것들보다 훨씬 더 좋은 성능을 보인다는 것을 보이고 있다. 이것을 generalization을 잘한다고 말할 수 있을 것 같다.(나만의 결론이다. 틀릴 수도 있다..)&lt;/p&gt;

&lt;p&gt;여기서는 1.tiny-imagenet, 2.imagenet, 3.cifar-100 등 유명한 classification 위주의 dataset에 대해서 train해보았다고 말하고 있다.&lt;/p&gt;

&lt;p&gt;이걸 text에 바로 적용하기에는 문제가 있는데, 먼저 text는 image처럼 연속적인 픽셀값으로 이루어져 있는 것이 아니기 때문이다.
그렇다면 어떻게 해야 할까? mixup 기반의 method를 nlp에도 apply한 논문이 있는데, &lt;a href=&quot;https://arxiv.org/pdf/2004.12239.pdf&quot;&gt;mixtext&lt;/a&gt; 가 바로 그것이다.
이번 ACL 2020에 accept된 따끈따끈한 paper이다. 여기서 주요 contribution으로 주장하는 것은, mixup idea를 문장에 바로 적용할수가 없으니까,
hidden layer에 적용해보자! 이다. 이것은 어떻게 보면 manifold mixup의 한 형태로 볼 수 있을 것 같다.
이 아이디어는 논문 안에 있는 도식도를 보면 바로 이해가 잘 된다. 저자들은 이것을 mixtext로 칭하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/illustrations/mixtext.png&quot; alt=&quot;image2&quot; /&gt;&lt;/p&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">이번에 연구 주제와 관련되어서 mixup 기반의 논문들을 읽어보고 공부하게 되었다. 여기서 중요하다고 느꼈던 점과 읽었던 부분들을 정리해보려고 한다. 시간이 지나면 다시 까먹을 것 같아서, 미리미리 정리해두는게 좋을것 같다. (정리한 부분은 순전히 내가 읽고 받아들인 대로 적은 것이기 떄문에, 틀린 부분이 있을 수 있고, 잘못된 부분이 있다면 댓글로 알려주시면 정말 감사하겠습니다..ㅎㅎ)</summary></entry><entry><title type="html">논문 리뷰_pie</title><link href="http://localhost:4000/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0_PIE/" rel="alternate" type="text/html" title="논문 리뷰_pie" /><published>2020-08-04T00:00:00+09:00</published><updated>2020-08-04T00:00:00+09:00</updated><id>http://localhost:4000/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0_PIE</id><content type="html" xml:base="http://localhost:4000/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0_PIE/">&lt;h1 id=&quot;parallel-iterative-edit-models-for-local-sequence-transduction&quot;&gt;Parallel Iterative Edit Models for Local Sequence Transduction&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/D19-1435.pdf&quot;&gt;pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-1.png&quot; alt=&quot;slide1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-2.png&quot; alt=&quot;slide2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-3.png&quot; alt=&quot;slide3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-4.png&quot; alt=&quot;slide4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-5.png&quot; alt=&quot;slide5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-6.png&quot; alt=&quot;slide6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-7.png&quot; alt=&quot;slide7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-8.png&quot; alt=&quot;slide8&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-9.png&quot; alt=&quot;slide9&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-10.png&quot; alt=&quot;slide10&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-11.png&quot; alt=&quot;slide11&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-12.png&quot; alt=&quot;slide12&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-13.png&quot; alt=&quot;slide13&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-14.png&quot; alt=&quot;slide14&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-15.png&quot; alt=&quot;slide15&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/slides/pie-16.png&quot; alt=&quot;slide16&quot; /&gt;&lt;/p&gt;</content><author><name>Soyoung Yoon</name></author><summary type="html">Parallel Iterative Edit Models for Local Sequence Transduction</summary></entry></feed>